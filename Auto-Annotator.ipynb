{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Class RetinaNet Auto-Annotator"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Author: Andrew Shepley \n",
    "Contact: asheple2@une.edu.au (alternative email: andreashepley01@gmail.com)\n",
    "Source: Location Invariance/U-Infuse \n",
    "Purpose: \n",
    "(a) single class automatic annotation of images\n",
    "(b) generate 1 xml file per image \n",
    "(c) custom class name\n",
    "NOTE: All annotations will be saved in the .annotations/ dir in a folder bearing the same name as the datasets folder containing the images that will be annotated, e.g. if you annotate images in ./datasets/pig/ the annotations will be stored in ./annotations/pig/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.inference import *\n",
    "from scripts.preprocessing import *\n",
    "from scripts.auto_annotation import *\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# use this environment flag to change which GPU to use\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the contents of ../datasets. First ensure you place all the datasets to be annotated in ../datasets. \n",
    "get_all_datasets('./datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose one of the datasets, e.g. SS_rhino\n",
    "folder = 'demo/'\n",
    "#specify class name\n",
    "classes = {\"rhinoceros\"} \n",
    "#select your confidence threshold. A confidence threshold of 50 means all detections with confidence >=50 will be retained.\n",
    "user_selected_confidence = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose the auto-annotator. \n",
    "model_dir = './pretrained_models'\n",
    "chosen_model = 'single_class_annotator.h5'\n",
    "#load the model\n",
    "model = choose_inference_model(model_dir, chosen_model)\n",
    "class_mapping_file = os.path.join(model_dir,chosen_model[:-2]+\"csv\")\n",
    "write_class_file(class_mapping_file, classes)\n",
    "confidence_threshold = set_confidence_threshold(user_selected_confidence) \n",
    "unannotated_dataset = os.path.join('./datasets',folder)\n",
    "images_to_annotate = generate_list_of_images(unannotated_dataset) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for each_im in images_to_annotate:\n",
    "    #perform object detection \n",
    "    processed_image, object_detection_data = inference_per_image(unannotated_dataset, model, each_im, class_mapping_file, confidence_threshold)\n",
    "    annotation = RetinaNet_Auto_Annotator(unannotated_dataset, each_im, object_detection_data, processed_image.shape, confidence_threshold)\n",
    "    #write the xml file for this image\n",
    "    annotation.write_xml_file()\n",
    "  \n",
    "    #displays image. comment out if you don't want visualisation.\n",
    "    img = Image.fromarray(processed_image, 'RGB')\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
